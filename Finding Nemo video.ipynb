{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features_ratio(img0,img1):\n",
    "    detector = cv2.ORB_create(100) # at most 100 descriptors\n",
    "    kps0, desc0 = detector.detectAndCompute(img0, None)\n",
    "    kps1, desc1 = detector.detectAndCompute(img1, None)\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, False)\n",
    "    \n",
    "    try:\n",
    "        matches01 = matcher.knnMatch(desc0, desc1, k=2)\n",
    "        matches10 = matcher.knnMatch(desc1, desc0, k=2)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    def ratio_test(matches, thr):\n",
    "    # Input: List of matches and threshold\n",
    "    # Output: List of \"good\" matches\n",
    "        good_matches = []\n",
    "        for m in matches:\n",
    "            ratio = m[0].distance/m[1].distance # Best match distance / Second best match distance\n",
    "            if ratio < thr:\n",
    "                good_matches.append(m[0]) # Keep the best match\n",
    "        return good_matches\n",
    "\n",
    "    thr = 0.825\n",
    "    good_matches01 = ratio_test(matches01,thr)\n",
    "    good_matches10 = ratio_test(matches10, thr)\n",
    "    \n",
    "    good_matches10_ = [(m.trainIdx, m.queryIdx) for m in good_matches10]\n",
    "    final_matches = [m for m in good_matches01 if (m.queryIdx, m.trainIdx) in good_matches10_]\n",
    "\n",
    "    points = np.array([kps0[m.queryIdx].pt for m in final_matches], np.uint8)\n",
    "    return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features_homography(img0, img1):\n",
    "    detector = cv2.ORB_create(50)\n",
    "    kps0, fea0 = detector.detectAndCompute(img0, None)\n",
    "    kps1, fea1 = detector.detectAndCompute(img1, None)\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, False)\n",
    "    matches = matcher.match(fea0, fea1)\n",
    "    pts0 = np.float32([kps0[m.queryIdx].pt for m in matches]).reshape(-1,2)\n",
    "    pts1 = np.float32([kps1[m.trainIdx].pt for m in matches]).reshape(-1,2)\n",
    "    H, mask = cv2.findHomography(pts0, pts1, cv2.RANSAC, 3.0) #last argument = internal RANSAC param\n",
    "    \n",
    "    final_matches = [m for i,m in enumerate(matches) if mask[i]]\n",
    "    worst_match = sorted([m.distance for m in final_matches])[-1]\n",
    "    \n",
    "    if worst_match < 100:\n",
    "        points = np.array([kps0[m.queryIdx].pt for m in final_matches], np.uint8)\n",
    "    else:\n",
    "        points = []\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0 = cv2.imread(\"../opencv-np-workshop/data/img/nemo.jpg\")\n",
    "img1 = cv2.imread(\"../opencv-np-workshop/data/img/nemo-sea.jpg\")\n",
    "match_features_homography(img0,img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rect(points):\n",
    "    xx, yy = zip(*points)\n",
    "    min_x = min(xx); min_y = min(yy); max_x = max(xx); max_y = max(yy)\n",
    "    return (min_x, min_y), (max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_detector(template,video,finder):\n",
    "    img0 = cv2.imread(template, 0)\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    i = 0\n",
    "    ret = True\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            try:\n",
    "                points = finder(img0, frame2gray)\n",
    "                if points.shape[0]>4:\n",
    "                    i+=1 \n",
    "                    top_left, bottom_right = calc_rect(points)                \n",
    "                    cv2.rectangle(frame, top_left,bottom_right,(0,255,0),5)\n",
    "                    cv2.imwrite(\"../DEMO/nemo/abc_\"+str(i+1)+'.png',frame)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"../opencv-np-workshop/data/video/Findet Nemo - Trailer.mp4\"\n",
    "template = \"../opencv-np-workshop/data/img/nemo.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_detector(template,video,match_features_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_detector(template,video,match_features_homography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
